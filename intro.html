<!DOCTYPE html>
<html>
<head>
	<meta charset='utf-8' />
	<title>精品课程</title>
	<link rel="stylesheet" type="text/css" href="style/basic.css">
	<link rel="stylesheet" type="text/css" href="style/intro.css">
</head>
<body >
<div id="header"></div>
<div id="nav">
<ul>
	<li><a href="index.html">首 页</a></li>
	<li><a href="intro.html" class="current">课 程 介 绍</a></li>
	<li><a href="compete.html">竞 赛 事 项</a></li>
	<li><a href="download.html">学 习 资 源</a></li>
	<li class="last"><a href="about.html">俱 乐 部</a></li>
</ul>
</div>
<div id="anc">
	<ul>
		<li><h3>目录</h3></li>
		<li><a href="#1">&sdot;（一）信息检索与Web搜索</a></li>
		<li><a href="#2">&sdot;（二）数据挖掘</a></li>
		<li><a href="#3">&sdot;（三）机器学习</a></li>
		<li><a href="#4">&sdot;（四）自然语言处理</a></li>
		<li><a href="#5">&sdot;（五）知识表示和语义技术</a></li>
		<li><a href="#6">&sdot;（六）数学基础</a></li>
	</ul>
</div>
<div id="content">
	<h1>数 据 挖 掘 知 识 体 系</h1>
	<p>	越来越多的应用涉及到大数据，而这些大数据的属性、包括数量、速度、多样性等等都是呈现了大数据不断增长的复杂性。从而，大数据的分析方法在大数据领域就显得尤为重要，可以说是决定最终信息是否有价值的决定性因素。</p>
	<p> 从大数据创造价值是一个多步骤过程，包括：数据获取、信息抽取和清理、数据整合，建模和分析，解释和部署等。大数据分析的普遍方法理论，主要与以下几个部分的知识有着密切关联。</p>
	
	<h3><a name="1">（一）信息检索与Web搜索(Information Retrieval and Web Search)：</a></h3> <p>信息检索是指从大规模数据集合中搜索满足我们需求的信息（通常是非格式化数据，如文本）；</p>
	<p>1. 爬虫（crawling）：这是数据获取的基础，经过这么多年的发展，除了面对surface web（即表层Web，由网页沟通，网页之间通过超链接关联）的常用爬虫，各种面对垂直领域和特定主题的爬虫（focused crawler)成为热点。他是实现去哪儿，etao等站点的基础。另一方面，随着各种动态页面技术的发展，以及javascript客户端类库的丰富和普及，包括各种动态页面的深度网络(deep web）大量出现，相比surface web中page由超链接关联，这里的交互通过表单填充和大量HTTP请求（包括Ajax等异步调用）来完成页面的跳转和关联，因此deep web crawler也成为热点。</p>
	<p>2. 评分（Scoring）& 排序（Ranking）: 对于信息检索来说，最重要的是：scoring & ranking，即评分和排序。从最早的对于网页的评分和排序，到后来的多媒体（如图片，视频），对于论坛的帖子，一直到目前针对实体的评分和排序，也就是说万物皆可排序。这里的评分和排序不仅需要刻画排序对象和查询（query，或用户需求,information need)之间的相关性，还需要刻画对象本身的重要程度以及其他的因素（如对广告排序和评分，还需要考虑广告主的bid price，即出价等），所以评分和排序可以分成2部分，查询相关和查询无关。</p>
	<p>3.展现：在搜索引擎的展现方面，也有了单一搜索，到元搜索(meta search，整合多个搜索引擎），联邦搜索（federated search，更多面向企业搜索），以及aggregated search（目前各种搜索引擎的发展趋势，包括mashup, 各种媒体或数据搜索的一体化展现，以及web服务的整合，其实百度的框计算也可以算是这方面的一种体现）。</p>
	<p>4.信息集成：为了完成各种整合或aggregation，信息集成是必不可少的。早期的搜索引擎关心near duplication detection（近重复检测，用来监控网页的变化等）,目前还包括entity resolution（检测相同实体），以及schema matching（模式匹配，特别在知识图谱环境下）。目前还包括entity resolution（检测相同实体），以及schema matching（模式匹配，特别在知识图谱环境下）。</p>
	<p>5.数据抽取（数据抽取）：为了获得各种对象甚至实体，data extraction（数据抽取）是必不可少的步骤，如前面所说的web table和list的抽取（面对这些半结构化数据的抽取）是解决deep web抽取（无法直接访问到后台数据库来获得信息的一个有效手段）另外，针对各种评论站点，sentiment analysis（情感分析，正面，负面等）, opinion mining（观点挖掘）也逐步被重视。</p>
	<h3><a name="2">（二）数据挖掘(Data Mining)：</a></h3><p>大数据分析的理论核心就是数据挖掘算法，指从大量的数据中通过算法搜索隐藏于其中信息的过程。正是因为有这些数据挖掘的算法，我们才能更快速的处理大数据；</p>
	<p>1.内容挖掘（content mining）：</p>
	<p>（1）Data preprocessing –数据预处理：通常，我们得到的实际数据是“脏”的，存在种种问题，而数据预处理的目的就是提高数据的质量。其重点是Data cleaning（数据清理，包括处理缺失值、噪音数据、奇异值等），Data transformation（数据变换，包括对数据的标准化、归一化、离散化等）等。</p>
	<p>（2）Information Integration – 信息集成：不同来源（如不同的网站）的数据格式不同，因此我们需要将它们采用统一的规范，集成到一起，以供展示或分析。前面提到的去哪儿或etao的例子是大家最容易理解的信息集成，这个在后面介绍语义技术时还会说。</p>
	<p>2.结构挖掘（structure mining) ：</p>
	<p>（1）link analysis (链接分析），有两个非常重要的算法：Page Rank和HITS (Hypertext Induced Topic Search)。前者是Google专有的算法，用于衡量特定网页相对于搜索引擎索引中的其他网页而言的重要程度；后者则是根据指向此网页的超链接和此网页指向其它网页的情况来分析网页的重要性。</p>
	<p>（2）social network analysis（社交网络分析）包括各种如中心度(centrality)，连接度(betweenness),等基础指标，也包括连通分量(connected component），团集(clique)等。</p>
	<p>（3）graph mining（图挖掘）包括异常检测（outlier detection)，社区发现和演化（community detection & evolution)，链接预测（link prediction）等众多方面。</p>
	<p>（4）dynamic graph analysis （动态图分析）之前说的哪些都是针对静态图的（没有重点考虑图中节点和边变化的情况），这里主要考虑图的变化，包括时态分析(temporal analysis)、信息扩散(information diffusion）等，针对这一块，大家可以使用graphlab等工具来熟悉相关的算法。</p>
	<p>3.用途挖掘(usage mining)：</p>
	<p>即使用用户数据进行相应的挖掘任务，几个应用或相关算法包括：(1)learning to rank （学习排序）；
(2)collaborative filtering matrix factorization （推荐系统中的协同过滤，使用矩阵分解）；(3)ctr prediction（广告中的点击率预测）；(4)privacy information prediction / De-anonymization（隐私信息如性别年龄等预测，以及信息的去匿名化）；(5)association rule mining（利用用户交易数据的关联规则挖掘，最常用的就是大家熟知的购物篮问题）；</p>
	<h3><a name="3">（三）机器学习(Machine Learning)：</a></h3>
	<p>机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。通过机器学习算法，计算机从数据中自动分析获得规律，并利用规律对未知数据进行预测；</p>
	<p>1.supervised learning - 有监督的学习</p>
	<p>这里的学习主要是针对分类问题，例如，我们要将新闻分到政治、娱乐、体育等类别当中，监督学习就是通过已经标注好类别的新闻来学习一个模型，然后可以用这个模型来处理新的新闻。首先要明确分类问题（监督学习）的输入、输出，以及对训练集的要求。然后要清楚其的评价方法，包括ROC和AUC。了解三个常用的分类器：Decision Tree、Naive Bayes和Logistic Regression，以及它们的特点、区别等；</p>
	<p>2.Support Vector Machine –支持向量机</p>
	<p>另一个应用十分广泛的分类器。这里除了最为基本的针对二分类问题的SVM，还由一些变种，例如one-class SVM以及SVM Rank；</p>
	<p>3.Unsupervised Learning –无监督学习</p>
	<p>指聚类方法，将数据根据它们之间的关系，分到若干个类别或群体当中。主要包括K-means聚类和层次聚类方法。也包括 Principal Component Analysis –主成分分析，PCA。它是非常常用的一种特征提取方法，将原特征空间旋转到新的空间中，找到第一主成分，它表示最多的原始数据的信息，第二主成分则表示次多的信息，并且主成分之间互不相关。它通常用来处理某些模型对特征的共线性敏感的问题，以及对数据进行降维；</p>
	<p>4.Semi-supervised Learning –半监督学习</p>
	<p>半监督学习是监督学习与无监督学习相结合的一种学习方法。它主要考虑如何利用少量的标注样本和大量的未标注样本进行训练和分类的问题，可以利用未标注的样本所提供的信息，来提高模型的效果。常用的方法有：EM、Co-training、PU-Learning以及Biased-SVM。</p>
	<h3><a name="4">（四）自然语言处理(Natural Language Processing)：</a></h3>	
	<p>对于文本类型的数据，自然语言处理是必不可少的一门学科。通俗的讲，自然语言处理是探讨如何让计算机“理解”自然语言；</p>
	<p>1. Language Model –语言模型，语言模型的目的是建立一个能够描述给定词序列在语言中的出现的概率的分布，根据语言客观事实而进行的语言抽象数学建模。重点是n-gram语言模型，它通过条件概率来表示文档中的词：一个词出现的概率，在某一个词A之后，出现词B的概率。对于language model，各种搜索引擎公司都提供n-gram library，提交一个词（或组合），给出其出现的概率等；</p>
	<p>2. Topic Model –主题模型，重点讲Latent Dirichlet Allocation (LDA)。这是一种无监督机器学习技术，可以用来识别文档集或语料库中潜藏的主题信息，将不同的文档归类到不同的主题当中，每一个主题是用一系列的词语来表示。它采用了词袋（bag of words）的方法，将每一篇文档视为一个词频向量，从而将文本信息转化为了易于建模的数字信息。当然也包括早期的如LSI（隐语义搜索），pLSA（概率隐层语义分析）等；</p>
	<p>3. Graphical Modeling - 图模型，用图形模式表达基于概率相关关系的模型的总称，在信息处理、自然语言处理领域得到了广泛应用。特别包括Maximum Entropy Models –最大熵模型，Hidden Markov Models –隐马尔科夫模型，Conditional Random Fields –条件随机场。三个统计模型被广泛的应用于序列标注问题当中。例如从文本中识别组织机构名称，通过已经标注的文档学习模型，然后在新的文本中抽取组织机构名称。</p>

	<h3><a name="5">（五）知识表示和语义技术(Knowledge Representation and Semantic Technologies)：</a> </h3><p>相比前面所提到的智能算法不同，这里更强调智能数据（smart data），研究数据的表示，尤其是语义表示和上层对应的推理、查询、和语义搜索等应用涉及到的技术；</p>
	<p>1.graph model vs. ER vs XML （图模型和传统关系型数据库ER模型的比较，和XML 基于树模型在语法语义上的比较）：graph model的代表包括RDF (resource description framework, W3c的标准，也包括前面在commoncrawl中提到的RDFa，和microformats等，是RDF的变种，作为各种轻量级知识表示和交换语言可以嵌入到网页中供机器处理和理解，最典型的例子包括在社交站点主页中包含foaf，在各种网站中为了搜素引擎优化嵌入schema.org分类；</p>
	<p>2.OWL vs prolog (closed word assumption vs. open word assumption)：OWL也是W3C标准，代表web ontology language，本体语言；后者是早起人工智能（专家系统）用的prolog，这也是开放世界假设和封闭世界假设的比较。OWL是开放的，对于没有定义的内容是未知，而对于封闭世界的假设，对于未定义的就是否。目前网上各种领域本体如医疗方面的snomed-ct，药物方面drugbank，通用的如dbpedia ontology等都很多。</p>
	<h3><a name="6">（六）数学基础：</a></h3><p>
	<p>除了上面这些和计算机相关的课程，数学基础知识是其基础。上述的许多课程，都会涉及到数学知识，如概率论、代数、最优化等等，因此，数学的基础知识也是必不可少的内容。</p>
	<p>最后说一下：数学基础数学基础知识，涵盖如下几个课程：<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.概率论与数理统计，包括常见的分布，假设检验，参数估计，方差分析，抽样理论等；<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.高等代数，主要是矩阵分析中的知识；<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.运筹学，即最优化理论，包括无约束和有约束的极值问题，梯度下降法等；<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.离散数据，包括图论，数理逻辑等。<br/>
	<p>当然这些课程并没有包括大数据挖掘的全部，多媒体挖掘，计算机视觉、数据可视化、并行计算和分布式存储等都未涉及。</p>
	<p>数据挖掘和数据仓库是融合与互动发展的，其学术研究价值和应用研究前景将是令人振奋的。它是数据挖掘专家、数据仓库技术人员和行业专家共同努力的成果，更是广大渴望从数据库“奴隶”到数据库“主人”转变的企业最终用户的通途。</p>
	
	<p class="more-intro"><a href="http://www.china-cloud.com/zhongyunxy/20140728_41388.html"> 引用自“王昊奋：大数据挖掘知识体系与人才培训”</a></p> 
</div>
<div id="footer">
<p>CopyRight 2015  广东工业大学 应用数学学院</p>
<p>联系电话：020-87083272  E-mail:yysxxy@gdut.edu.cn</p>
<p>地址：中国 广东省 广州市 天河区 迎龙路 161号  邮编：510520</p>
</div>

</body>
</html>